{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = PromptTemplate (\n",
    "    input_variables=[\"name\", 'city'],\n",
    "    template= \"\"\"\n",
    "write two more sentense based on text in triple ticks\n",
    "text:\n",
    "'''Hi my name is {name}.\\\n",
    "I live in {city}.\\\n",
    "'''\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['city', 'name'], template=\"\\nwrite two more sentense based on text in triple ticks\\ntext:\\n'''Hi my name is {name}.I live in {city}.'''\\n\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt_model = \"gpt-3.5-turbo-0125\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x758ede61f850>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x758ede629660>, model_name='gpt-3.5-turbo-0125', temperature=0.3, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI (temperature = 0.3, model= gpt_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-16011f94-90c2-45e0-82f2-23ce7b398a2a-0', usage_metadata={'input_tokens': 10, 'output_tokens': 9, 'total_tokens': 19})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke (\"sam here?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "# llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Safeer!\\n\\nAs for your question, the best language to start writing code depends on several factors, such as:\\n\\n1. Your goals: Are you interested in web development, mobile app development, data analysis, or something else?\\n2. Your experience: Have you worked with programming concepts before, or are you a complete beginner?\\n3. The type of projects: Do you want to build games, chatbots, or something more complex?\\n\\nThat being said, here are some popular languages that are great for beginners:\\n\\n1. **Python**: Known for its simplicity, readability, and ease of use, Python is an excellent choice for beginners. It\\'s also a versatile language with applications in web development, data analysis, machine learning, and more.\\n2. **JavaScript**: As the primary language for web development, JavaScript is a great choice if you want to build interactive web pages, work on client-side scripting, or create web applications. Node.js allows you to use JavaScript for server-side programming as well.\\n3. **HTML/CSS**: Not a programming language per se, but essential for building websites and web applications. HTML (Hypertext Markup Language) is used for structuring content, while CSS (Cascading Style Sheets) is used for styling and layout.\\n4. **Java**: A popular language for beginners, Java is known for its platform independence, making it a great choice for Android app development or building enterprise-level applications.\\n5. **Swift**: If you\\'re interested in iOS or macOS app development, Swift is the way to go. It\\'s an easy-to-learn language with a lot of built-in features and a growing community.\\n\\nRemember, there\\'s no single \"best\" language for beginners. The most important thing is to choose a language that aligns with your goals and interests, and to have fun learning!\\n\\nWhat do you think? Which language are you leaning towards, or would you like me to suggest some resources to help you get started?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm.invoke(\"My name is safeer, best language to start writing code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x758ede63f5e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x758edf173340>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "llm = ChatOpenAI(model= gpt_model)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['user_inp'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_inp'], template='you are a out class technical writer.    who to use RAG in llm.\\n    {user_inp}    \\n    '))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat =  ChatPromptTemplate.from_template (\n",
    "    \"\"\"you are a out class technical writer.\\\n",
    "    who to use RAG in llm.\n",
    "    {user_inp}    \n",
    "    \"\"\"\n",
    ")\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['user_inp'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_inp'], template='you are a out class technical writer.    who to use RAG in llm.\\n    {user_inp}    \\n    '))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x758ede63f5e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x758edf173340>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat | llm\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = \"My name is Safeer\" #{\"userdata\":\"My name is Safeer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "output = JsonOutputToolsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='\\nWhat is the best name to describe a company that makes {product}.\\nonly give single name of the company\\n'))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1 = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "What is the best name to describe a company that makes {product}.\n",
    "only give single name of the company\n",
    "\"\"\"\n",
    ")\n",
    "chain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x758ede63f5e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x758edf173340>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='\\nWhat is the best name to describe a company that makes {product}.\\nonly give single name of the company\\n'))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = llm | chain1 \n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product_name = \"High power Laptops for AI worloads\"\n",
    "\n",
    "ans = name.invoke(product_name)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompt_values.ChatPromptValue"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat is the best name to describe a company that makes content='1. Dell Precision 7750: This laptop is equipped with powerful Intel Xeon processors, NVIDIA Quadro RTX graphics, up to 128GB of RAM, and up to 8TB of storage. It is designed to handle demanding AI workloads with ease.\\\\n\\\\n2. HP ZBook Fury 17 G7: This laptop features high-performance Intel Core i9 processors, NVIDIA Quadro RTX graphics, up to 128GB of RAM, and up to 10TB of storage. It is ideal for AI professionals who require a powerful and reliable workstation.\\\\n\\\\n3. Lenovo ThinkPad P17: This laptop offers powerful Intel Core i9 processors, NVIDIA Quadro RTX graphics, up to 128GB of RAM, and up to 6TB of storage. It is designed to handle intensive AI workloads and deliver exceptional performance.\\\\n\\\\n4. MSI WS66: This laptop is powered by Intel Core i9 processors, NVIDIA Quadro RTX graphics, up to 64GB of RAM, and up to 4TB of storage. It is a high-performance workstation that can handle complex AI tasks with ease.\\\\n\\\\n5. ASUS ProArt StudioBook Pro X: This laptop features Intel Core i7 or i9 processors, NVIDIA Quadro RTX graphics, up to 128GB of RAM, and up to 6TB of storage. It is a powerful workstation that is ideal for AI professionals who require high performance and reliability.' response_metadata={'token_usage': {'completion_tokens': 291, 'prompt_tokens': 15, 'total_tokens': 306}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-06ebef83-96b2-447d-9512-0cbea5e6458c-0' usage_metadata={'input_tokens': 15, 'output_tokens': 291, 'total_tokens': 306}\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ans.messages[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = gpt_model\n",
    "llm = OpenAI(model= llm_model)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(\n",
    "\"You are kind maths instructor.\\\n",
    "question: what is {question}\"  \n",
    ")\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = template.format(question=\"back proppagation\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'You are a kind maths instructor. Question: what is backpropagation', 'history': '', 'response': \"Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network's performance. Would you like more information on how it works?\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import ConversationChain, PromptTemplate\n",
    "\n",
    "# Assuming you have the llm_model defined elsewhere (e.g., \"text-davinci-003\")\n",
    "llm_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "llm = ChatOpenAI(model=llm_model)\n",
    "\n",
    "# Create the PromptTemplate\n",
    "template = PromptTemplate.from_template(\n",
    "    \"You are a kind maths instructor. Question: what is {question}\"\n",
    ")\n",
    "memory=ConversationBufferMemory()\n",
    "# Create a ConversationChain instance\n",
    "chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "prompt=template.format(question=\"backpropagation\")\n",
    "# Use the chain to generate a response with the template\n",
    "response = chain.invoke(prompt)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: You are a kind maths instructor. Question: what is backpropagation\\nAI: Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network's performance. Would you like more information on how it works?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hallowene',\n",
       " 'history': \"Human: You are a kind maths instructor. Question: what is backpropagation\\nAI: Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network's performance. Would you like more information on how it works?\",\n",
       " 'response': 'I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hallowene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'derivation',\n",
       " 'history': 'Human: You are a kind maths instructor. Question: what is backpropagation\\nAI: Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network\\'s performance. Would you like more information on how it works?\\nHuman: hallowene\\nAI: I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?',\n",
       " 'response': 'Derivation is a mathematical process of finding the rate at which a function is changing at a specific point. It involves calculating the slope of the tangent line to the graph of the function at that point. Derivatives are used in calculus to solve various problems related to rates of change, optimization, and more. Is there a specific type of derivation you would like to know more about?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"derivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'did i ask you about hallowene',\n",
       " 'history': 'Human: You are a kind maths instructor. Question: what is backpropagation\\nAI: Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network\\'s performance. Would you like more information on how it works?\\nHuman: hallowene\\nAI: I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?\\nHuman: derivation\\nAI: Derivation is a mathematical process of finding the rate at which a function is changing at a specific point. It involves calculating the slope of the tangent line to the graph of the function at that point. Derivatives are used in calculus to solve various problems related to rates of change, optimization, and more. Is there a specific type of derivation you would like to know more about?',\n",
       " 'response': 'I apologize if I misunderstood your question earlier. You did mention \"hallowene\" in your previous response, but I was unable to provide any information on it. If there is anything else you would like to know or ask about, please feel free to let me know.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"did i ask you about hallowene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context ({\"input\":\"hallowene\"},\n",
    "                     {\"output\":\"Its an even in USA\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: You are a kind maths instructor. Question: what is backpropagation\\nAI: Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network\\'s performance. Would you like more information on how it works?\\nHuman: hallowene\\nAI: I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?\\nHuman: derivation\\nAI: Derivation is a mathematical process of finding the rate at which a function is changing at a specific point. It involves calculating the slope of the tangent line to the graph of the function at that point. Derivatives are used in calculus to solve various problems related to rates of change, optimization, and more. Is there a specific type of derivation you would like to know more about?\\nHuman: did i ask you about hallowene\\nAI: I apologize if I misunderstood your question earlier. You did mention \"hallowene\" in your previous response, but I was unable to provide any information on it. If there is anything else you would like to know or ask about, please feel free to let me know.\\nHuman: hallowene\\nAI: Its an even in USA\\nHuman: Not much, just hanging\\nAI: Cool'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer_as_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is hallowene',\n",
       " 'history': 'Human: You are a kind maths instructor. Question: what is backpropagation\\nAI: Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network\\'s performance. Would you like more information on how it works?\\nHuman: hallowene\\nAI: I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?\\nHuman: derivation\\nAI: Derivation is a mathematical process of finding the rate at which a function is changing at a specific point. It involves calculating the slope of the tangent line to the graph of the function at that point. Derivatives are used in calculus to solve various problems related to rates of change, optimization, and more. Is there a specific type of derivation you would like to know more about?\\nHuman: did i ask you about hallowene\\nAI: I apologize if I misunderstood your question earlier. You did mention \"hallowene\" in your previous response, but I was unable to provide any information on it. If there is anything else you would like to know or ask about, please feel free to let me know.\\nHuman: hallowene\\nAI: Its an even in USA\\nHuman: Not much, just hanging\\nAI: Cool',\n",
       " 'response': \"Halloween is a popular holiday celebrated in the United States and other countries on October 31st. It is known for activities such as trick-or-treating, costume parties, pumpkin carving, and haunted houses. The holiday has roots in the Celtic festival of Samhain and the Christian celebration of All Saints' Day. People often dress up in costumes, go door-to-door asking for candy, and decorate their homes with spooky decorations. It's a fun and festive time of year for many people!\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is hallowene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='You are a kind maths instructor. Question: what is backpropagation'),\n",
       " AIMessage(content=\"Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network's performance. Would you like more information on how it works?\"),\n",
       " HumanMessage(content='hallowene'),\n",
       " AIMessage(content='I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?'),\n",
       " HumanMessage(content='derivation'),\n",
       " AIMessage(content='Derivation is a mathematical process of finding the rate at which a function is changing at a specific point. It involves calculating the slope of the tangent line to the graph of the function at that point. Derivatives are used in calculus to solve various problems related to rates of change, optimization, and more. Is there a specific type of derivation you would like to know more about?'),\n",
       " HumanMessage(content='did i ask you about hallowene'),\n",
       " AIMessage(content='I apologize if I misunderstood your question earlier. You did mention \"hallowene\" in your previous response, but I was unable to provide any information on it. If there is anything else you would like to know or ask about, please feel free to let me know.'),\n",
       " HumanMessage(content='hallowene'),\n",
       " AIMessage(content='Its an even in USA'),\n",
       " HumanMessage(content='Not much, just hanging'),\n",
       " AIMessage(content='Cool'),\n",
       " HumanMessage(content='what is hallowene'),\n",
       " AIMessage(content=\"Halloween is a popular holiday celebrated in the United States and other countries on October 31st. It is known for activities such as trick-or-treating, costume parties, pumpkin carving, and haunted houses. The holiday has roots in the Celtic festival of Samhain and the Christian celebration of All Saints' Day. People often dress up in costumes, go door-to-door asking for candy, and decorate their homes with spooky decorations. It's a fun and festive time of year for many people!\")]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_memory': {'messages': [{'content': 'You are a kind maths instructor. Question: what is backpropagation',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': \"Thank you for the compliment! Backpropagation is a common algorithm used in training artificial neural networks. It is a method for calculating the gradient of the loss function with respect to the weights of the network. This gradient is then used to update the weights in the network in order to minimize the loss function and improve the network's performance. Would you like more information on how it works?\",\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': 'hallowene',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': 'I\\'m sorry, but I don\\'t have any information on \"hallowene.\" Is there anything else I can help you with?',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': 'derivation',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': 'Derivation is a mathematical process of finding the rate at which a function is changing at a specific point. It involves calculating the slope of the tangent line to the graph of the function at that point. Derivatives are used in calculus to solve various problems related to rates of change, optimization, and more. Is there a specific type of derivation you would like to know more about?',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': 'did i ask you about hallowene',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': 'I apologize if I misunderstood your question earlier. You did mention \"hallowene\" in your previous response, but I was unable to provide any information on it. If there is anything else you would like to know or ask about, please feel free to let me know.',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': 'hallowene',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': 'Its an even in USA',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': 'Not much, just hanging',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': 'Cool',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None},\n",
       "   {'content': 'what is hallowene',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False},\n",
       "   {'content': \"Halloween is a popular holiday celebrated in the United States and other countries on October 31st. It is known for activities such as trick-or-treating, costume parties, pumpkin carving, and haunted houses. The holiday has roots in the Celtic festival of Samhain and the Christian celebration of All Saints' Day. People often dress up in costumes, go door-to-door asking for candy, and decorate their homes with spooky decorations. It's a fun and festive time of year for many people!\",\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'ai',\n",
       "    'name': None,\n",
       "    'id': None,\n",
       "    'example': False,\n",
       "    'tool_calls': [],\n",
       "    'invalid_tool_calls': [],\n",
       "    'usage_metadata': None}]},\n",
       " 'output_key': None,\n",
       " 'input_key': None,\n",
       " 'return_messages': False,\n",
       " 'human_prefix': 'Human',\n",
       " 'ai_prefix': 'AI',\n",
       " 'memory_key': 'history'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate , PromptTemplate\n",
    "\n",
    "\n",
    "model_name = 'gpt-3.5-turbo-0125'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!env | grep OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1dcdc340>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1dcdda50>, model_name='gpt-3.5-turbo-0125', temperature=0.3, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=model_name, temperature=0.3)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a chemistry tutor')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template  = ChatPromptTemplate.from_messages (\n",
    "    [\n",
    "        (\"system\",\"You are a chemistry tutor\"),\n",
    "        (\"user\",   \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['name'], template='This is a message for {name}')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\n",
    "'This is a message for {name}'\n",
    ")\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['name'], template='This is a message for {name}')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | llm\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a chemistry tutor'),\n",
       " HumanMessage(content='what are the contribution of Einstein in chemistry?')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template.format_messages ( question = \"what are the contribution of Einstein in chemistry?\" )\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are helpfull tutor'),\n",
       " HumanMessage(content='what are the contribution of Einstein in chemistry?')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hey Sam, just wanted to say hi and see how you're doing. Hope everything is going well with you. Let's catch up soon and chat about what's been going on in our lives. Take care!\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 13, 'total_tokens': 56}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3b2dcef2-90bf-43e1-b978-d26fa3b69b07-0', usage_metadata={'input_tokens': 13, 'output_tokens': 43, 'total_tokens': 56})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke ({\"name\":\"sam\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StrOutputParser()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = chain | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Sam!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = chain2.invoke ({\"name\":\"sam. Just say Hi.\"})\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product'], template='make a name for a company that makes {product}')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = PromptTemplate(input_variables=[\"product\"], template= \"\"\"make a name for a company that makes {product}\"\"\")\n",
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['product'], template='make a name for a company that makes {product}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy=''), output_key='comp_name')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1 = LLMChain (llm=llm, prompt=prompt1, output_key=\"comp_name\" )\n",
    "chain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/safeer/Documents/ml/LLM-with-LangChain/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Intellilap Technologies'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=chain1.run(\"AI Laptop\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['comp_name', 'product'], template='suggent a marketing statage for a company name {comp_name} that is making {product} base product')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = PromptTemplate.from_template (\"suggent a marketing statage for a company name {comp_name} that is making {product} base product\")\n",
    "prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['comp_name', 'product'], template='suggent a marketing statage for a company name {comp_name} that is making {product} base product'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy=''), output_key='summery')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = LLMChain (llm = llm , prompt= prompt2, output_key=\"summery\")\n",
    "chain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = PromptTemplate.from_template ( \"translate the text provided into french, Text : {summery}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['summery'], template='translate the text provided into french, Text : {summery}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy=''), output_key='translation')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain3 = LLMChain (llm = llm , prompt= prompt3, output_key=\"translation\")\n",
    "chain3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialChain(verbose=True, chains=[LLMChain(prompt=PromptTemplate(input_variables=['product'], template='make a name for a company that makes {product}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy=''), output_key='comp_name'), LLMChain(prompt=PromptTemplate(input_variables=['comp_name', 'product'], template='suggent a marketing statage for a company name {comp_name} that is making {product} base product'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy=''), output_key='summery'), LLMChain(prompt=PromptTemplate(input_variables=['summery'], template='translate the text provided into french, Text : {summery}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ead1d0ee0b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ead1cfb0640>, openai_api_key=SecretStr('**********'), openai_proxy=''), output_key='translation')], input_variables=['product'], output_variables=['summery', 'translation'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collective_chain =  SequentialChain(chains=[chain1,chain2,chain3] ,\n",
    "                                    input_variables=[\"product\"],\n",
    "                                    output_variables=[\"summery\", \"translation\"], verbose=True)\n",
    "collective_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'product': 'ai robots',\n",
       " 'summery': \"1. Develop a strong brand identity: Create a sleek and modern brand image that reflects the advanced technology and innovation behind Synthetix Robotics' AI robots.\\n\\n2. Targeted advertising: Identify and target specific industries or markets where AI robots could be beneficial, such as manufacturing, healthcare, or retail. Utilize social media, online ads, and industry publications to reach potential customers.\\n\\n3. Showcase product features: Highlight the key features and capabilities of Synthetix Robotics' AI robots through product demonstrations, case studies, and testimonials from satisfied customers.\\n\\n4. Partner with industry influencers: Collaborate with influencers in the robotics or technology space to promote Synthetix Robotics' products and reach a wider audience.\\n\\n5. Attend industry events: Participate in trade shows, conferences, and other industry events to showcase Synthetix Robotics' AI robots and network with potential customers and partners.\\n\\n6. Offer free trials or demos: Allow potential customers to test out Synthetix Robotics' AI robots through free trials or demonstrations to help them understand the value and benefits of the product.\\n\\n7. Provide excellent customer support: Ensure that customers receive prompt and helpful support before, during, and after purchasing Synthetix Robotics' AI robots to build trust and loyalty.\\n\\n8. Collect and utilize customer feedback: Gather feedback from customers to continuously improve the product and tailor marketing strategies to better meet customer needs and preferences.\\n\\n9. Collaborate with universities and research institutions: Partner with academic institutions to showcase the cutting-edge technology and research behind Synthetix Robotics' AI robots and establish credibility in the industry.\\n\\n10. Create a referral program: Encourage satisfied customers to refer friends and colleagues to Synthetix Robotics' AI robots through a referral program with incentives such as discounts or rewards.\",\n",
       " 'translation': \"1. DÃ©velopper une identitÃ© de marque forte : CrÃ©ez une image de marque Ã©lÃ©gante et moderne qui reflÃ¨te la technologie de pointe et l'innovation derriÃ¨re les robots AI de Synthetix Robotics.\\n\\n2. PublicitÃ© ciblÃ©e : Identifiez et ciblez des industries ou marchÃ©s spÃ©cifiques oÃ¹ les robots AI pourraient Ãªtre bÃ©nÃ©fiques, tels que la fabrication, les soins de santÃ© ou le commerce de dÃ©tail. Utilisez les mÃ©dias sociaux, les annonces en ligne et les publications sectorielles pour atteindre les clients potentiels.\\n\\n3. Mettre en avant les fonctionnalitÃ©s du produit : Mettez en lumiÃ¨re les principales fonctionnalitÃ©s et capacitÃ©s des robots AI de Synthetix Robotics grÃ¢ce Ã  des dÃ©monstrations de produit, des Ã©tudes de cas et des tÃ©moignages de clients satisfaits.\\n\\n4. Collaborer avec des influenceurs de l'industrie : Collaborez avec des influenceurs dans le domaine de la robotique ou de la technologie pour promouvoir les produits de Synthetix Robotics et toucher un public plus large.\\n\\n5. Participer Ã  des Ã©vÃ©nements de l'industrie : Prenez part Ã  des salons professionnels, des confÃ©rences et d'autres Ã©vÃ©nements de l'industrie pour prÃ©senter les robots AI de Synthetix Robotics et rÃ©seauter avec des clients et partenaires potentiels.\\n\\n6. Proposer des essais ou dÃ©monstrations gratuits : Permettez aux clients potentiels de tester les robots AI de Synthetix Robotics grÃ¢ce Ã  des essais gratuits ou des dÃ©monstrations pour les aider Ã  comprendre la valeur et les avantages du produit.\\n\\n7. Fournir un excellent service client : Assurez-vous que les clients reÃ§oivent un support rapide et utile avant, pendant et aprÃ¨s l'achat des robots AI de Synthetix Robotics pour Ã©tablir la confiance et la fidÃ©litÃ©.\\n\\n8. Collecter et utiliser les retours des clients : Rassemblez les retours des clients pour amÃ©liorer continuellement le produit et adapter les stratÃ©gies marketing pour mieux rÃ©pondre aux besoins et prÃ©fÃ©rences des clients.\\n\\n9. Collaborer avec les universitÃ©s et institutions de recherche : Partenariat avec des institutions acadÃ©miques pour mettre en avant la technologie de pointe et la recherche derriÃ¨re les robots AI de Synthetix Robotics et Ã©tablir une crÃ©dibilitÃ© dans l'industrie.\\n\\n10. CrÃ©er un programme de parrainage : Encouragez les clients satisfaits Ã  recommander les robots AI de Synthetix Robotics Ã  leurs amis et collÃ¨gues grÃ¢ce Ã  un programme de parrainage avec des incitations telles que des rÃ©ductions ou des rÃ©compenses.\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = collective_chain.invoke (input={'product':\"ai robots\"})\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
